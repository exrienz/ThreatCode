# ==============================================================================
# ThreatCode Maker-Checker Configuration with Custom Providers
# ==============================================================================
# This example shows how to use two different custom LLM providers:
# - Maker: Your primary scanning LLM (faster/cheaper model)
# - Checker: Validation LLM to eliminate false positives (better model)
# ==============================================================================

# ------------------------------------------------------------------------------
# MAKER LLM (Primary Scanner) - Custom Provider
# ------------------------------------------------------------------------------
LLM_PROVIDER=custom
CUSTOM_API_KEY=sk-maker-your-api-key-here
CUSTOM_MODEL=llama-3-70b-instruct
CUSTOM_PROVIDER_URL=https://api.together.xyz/v1

# If your custom provider is not in the allowlist, you need to enable this
# WARNING: Only enable for trusted providers
ALLOW_ALL_CUSTOM_URLS=true

# ------------------------------------------------------------------------------
# CHECKER LLM (Validator) - Custom Provider
# ------------------------------------------------------------------------------
# Enable maker-checker mode
ENABLE_CHECKER=true

# Configure the checker to use a different custom provider
CHECKER_PROVIDER=custom
CHECKER_CUSTOM_API_KEY=sk-checker-your-api-key-here
CHECKER_CUSTOM_MODEL=claude-3-opus-20240229
CHECKER_CUSTOM_PROVIDER_URL=https://api.anthropic.com/v1

# ------------------------------------------------------------------------------
# Rate Limiting
# ------------------------------------------------------------------------------
# Adjust based on your provider's rate limits
RATE_LIMIT_DELAY=0.5

# ==============================================================================
# USAGE NOTES
# ==============================================================================
#
# Example 1: Using Ollama (Local) for Maker + Cloud for Checker
# ----------------------------------------------------------------
# LLM_PROVIDER=custom
# CUSTOM_API_KEY=ollama
# CUSTOM_MODEL=codellama:13b
# CUSTOM_PROVIDER_URL=http://localhost:11434/v1
#
# ENABLE_CHECKER=true
# CHECKER_PROVIDER=openai
# CHECKER_OPENAI_API_KEY=sk-...
# CHECKER_OPENAI_MODEL=gpt-4
#
# Example 2: Using Together.ai for Both
# ----------------------------------------------------------------
# LLM_PROVIDER=custom
# CUSTOM_API_KEY=your-together-key
# CUSTOM_MODEL=meta-llama/Llama-3-70b-chat-hf
# CUSTOM_PROVIDER_URL=https://api.together.xyz/v1
#
# ENABLE_CHECKER=true
# CHECKER_PROVIDER=custom
# CHECKER_CUSTOM_API_KEY=your-together-key
# CHECKER_CUSTOM_MODEL=meta-llama/Llama-3.1-405b-instruct-turbo
# CHECKER_CUSTOM_PROVIDER_URL=https://api.together.xyz/v1
#
# Example 3: Using Groq for Maker + OpenRouter for Checker
# ----------------------------------------------------------------
# LLM_PROVIDER=custom
# CUSTOM_API_KEY=gsk_...
# CUSTOM_MODEL=llama-3.1-70b-versatile
# CUSTOM_PROVIDER_URL=https://api.groq.com/openai/v1
#
# ENABLE_CHECKER=true
# CHECKER_PROVIDER=openrouter
# CHECKER_OPENROUTER_API_KEY=sk-or-...
# CHECKER_OPENROUTER_MODEL=anthropic/claude-3-opus
#
# ==============================================================================
